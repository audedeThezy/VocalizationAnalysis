{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocalization analysis in live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Titles / graduation etc\n",
    "- same color everywere for f0\n",
    "- understand the convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\de Witasse Thézy\\AppData\\Roaming\\Python\\Python38\\site-packages\\pandas\\core\\computation\\expressions.py:20: UserWarning: Pandas requires version '2.7.3' or newer of 'numexpr' (version '2.7.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import glob\n",
    "import librosa\n",
    "import time\n",
    "import libf0\n",
    "import statistics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "from skimage.restoration import denoise_tv_chambolle\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, IntSlider\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trigger and save by Avisoft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "basepath = \"D:\\\\data\\\\playback2T01\\\\ch2\"\n",
    "listRecordingsPath = glob.glob(os.path.join(basepath, '*.wav'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis step by step with interactive graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the fundamental frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters :\n",
    "With the widgets, you can make two parameters change :\n",
    "- the minmum fundamental frequency (fmin)\n",
    "- the hop leght (H), which is the size of the non overlapping part of the window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89017431e7d849679c95bfe2d9a59348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='VocNumber', max=12, min=-4), IntSlider(value=600, descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compute_and_show_f0(VocNumber, h, fmin, returnf0)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_and_show_f0(VocNumber, h, fmin, returnf0) :\n",
    "    y, sr = librosa.load(listRecordingsPath[VocNumber], sr = 300000)\n",
    "    \n",
    "    f0,_,_= libf0.salience(y, Fs=sr, N=500, H=h, F_min=fmin, F_max=90000, R=10.0, num_harm=10,\n",
    "        freq_smooth_len=11, alpha=0.9, gamma=0.0, constraint_region=None, tol=5, score_low=0.01, score_high=1.0)\n",
    "    times = librosa.times_like(f0, sr = sr,  hop_length = h)\n",
    "\n",
    "    D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    img = librosa.display.specshow(D, x_axis='ms', y_axis='linear', ax=ax,  sr=sr, fmin=20000, fmax=100000)\n",
    "\n",
    "    #ax.set(title='pYIN fundamental frequency estimation, duration = %f'%(duration))\n",
    "\n",
    "    ax.set_ylim(20000, 100000)\n",
    "\n",
    "    fig.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "\n",
    "    ax.plot(times, f0, label='f0 extimated with libf0', color='cyan', linewidth=3)\n",
    "\n",
    "    ax.legend(loc='upper right')\n",
    "    \n",
    "    if returnf0 :\n",
    "        return f0,times\n",
    "\n",
    "interact(compute_and_show_f0, VocNumber = 4, h=IntSlider(min=50, max=1000, step=50, value=600), \n",
    "         fmin = IntSlider(min=20000, max=50000, step=2000, value=38000),returnf0 = fixed(False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the vocalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8aa4f6814c444349f519dd9e0e23795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='VocNumber', max=12, min=-4), FloatSlider(value=0.5, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.find_voc(VocNumber, weight, width, plot, h=500, returnSteps=True)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_and_show_steps(data, width, plot=False):\n",
    "    dary = np.array(data)\n",
    "    dary -= np.average(dary)\n",
    "    step = np.hstack((np.ones(len(dary)), -1*np.ones(len(dary))))\n",
    "    dary_step = np.convolve(dary, step, mode='valid')\n",
    "    # Get the peaks of the convolution\n",
    "    peaks = signal.find_peaks(dary_step, width=width)[0]\n",
    "    \n",
    "    # plots\n",
    "    if plot :\n",
    "        plt.plot(dary)\n",
    "        plt.plot(dary_step/10)\n",
    "        for ii in range(len(peaks)):\n",
    "             plt.plot((peaks[ii], peaks[ii]), (min(min(dary_step/10), min(dary)) -2,max(max(dary),max(dary_step/10))+2), 'r')\n",
    "        plt.ylim([min(min(dary_step/10), min(dary))-2,max(max(dary),max(dary_step/10))+2])\n",
    "        plt.show()\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "def find_voc(VocNumber, weight, width, plot, h = 500, returnSteps = True) :\n",
    "    f0,times = compute_and_show_f0(VocNumber=VocNumber, h=h,fmin=38000, returnf0 = True)\n",
    "    plt.close()\n",
    "    x = np.array(f0)\n",
    "    #plt.plot(f0)\n",
    "    x_std = (x - x.mean()) / x.std()\n",
    "    x_denoiseP = (denoise_tv_chambolle(x_std, weight= weight))**2\n",
    "    x_denoiseN = -(denoise_tv_chambolle(x_std, weight= weight))**2\n",
    "    \n",
    "    stepsP = find_and_show_steps(x_denoiseP, width, plot)\n",
    "    stepsN = find_and_show_steps(x_denoiseN, width, plot)\n",
    "    \n",
    "    if returnSteps :\n",
    "        return [stepsP, stepsN,f0,times]\n",
    "    \n",
    "    \n",
    "interact(find_voc, VocNumber=4, weight=0.5, \n",
    "        width=IntSlider(min=2, max=30, step=2, value=10),\n",
    "        plot = fixed(True),\n",
    "         h=fixed(600),\n",
    "        returnSteps = fixed(False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5faa31b2ddb45858eb7203450d49642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4, description='VocNumber', max=12, min=-4), IntSlider(value=45000, desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.extract_vocalizationf0(VocNumber, noise_threshold, plot, h=500)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_vocalizationf0(VocNumber, noise_threshold, plot, h = 500):\n",
    "    stepsP, stepsN, f0, times = find_voc(VocNumber, weight = 0.5, width = 10, h = h, plot = False)\n",
    "    vocf0 = []\n",
    "    voctime = []\n",
    "    vocduration = [0]\n",
    "    for i in range(min(len(stepsP), len(stepsN))):\n",
    "        if np.mean(f0[stepsP[i]:stepsN[i]]) < noise_threshold :\n",
    "            continue\n",
    "        vocf0.append(list(f0[stepsP[i]:stepsN[i]]))\n",
    "        voctime.append(list(times[stepsP[i]:stepsN[i]]))\n",
    "        vocduration.append((times[stepsN[i]]) - times[stepsP[i]])\n",
    "\n",
    "    Name = listRecordingsPath[VocNumber].split(\"_\")[-1].split(\".\")[0]\n",
    "    \n",
    "    y, sr = librosa.load(listRecordingsPath[VocNumber], sr = 300000)\n",
    "    if plot :\n",
    "        plt.figure(figsize = (10,6))\n",
    "        ax = plt.gca()\n",
    "        D = librosa.amplitude_to_db(np.abs(librosa.stft(y)), ref=np.max)\n",
    "        img = librosa.display.specshow(D, x_axis='ms', y_axis='linear', ax=ax,  sr=sr, fmin=20000, fmax=100000)\n",
    "        ax.set(title='fundamental frequency estimation,\\n duration estimation = %f ms'%(vocduration[-1]))\n",
    "        ax.set_ylim(20000, 100000)\n",
    "        plt.colorbar(img, ax=ax, format=\"%+2.f dB\")\n",
    "        for vocnumber in range(len(vocf0)) :\n",
    "            ax.plot(voctime[vocnumber], vocf0[vocnumber], label='f0', color='cyan', linewidth=2, linestyle = '-')\n",
    "        ax.legend(loc='upper right')\n",
    "       \n",
    "interact(extract_vocalizationf0, VocNumber=4, noise_threshold=IntSlider(min=20000, max=70000, step=5000, value=45000), plot = fixed(True), \n",
    "         h=IntSlider(min=50, max=1200, step=50, value=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The general function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractRecordingsPaths(playback_time_str, basepath) :\n",
    "    \"\"\"return a list of wavefiles paths\"\"\"\n",
    "    # TODO : check that it's working\n",
    "    playback_time = time.strptime(playback_time_str, '%H-%M-%S')\n",
    "    listRecordingsPaths = glob.glob(os.path.join(basepath, '*.wav'))\n",
    "    listgoodtime = []\n",
    "    for RecordingPath in listRecordingsPaths :\n",
    "        recording_time_str = RecordingPath.split('_')[-2]\n",
    "        recording_time = time.strptime(recording_time_str, '%H-%M-%S')\n",
    "        if playback_time < recording_time : #on peut aussi ajouter un seuil pour que ce ne soit pas trop longtemps après ??\n",
    "            listgoodtime.append(RecordingPath)\n",
    "    return listgoodtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_steps(data) :\n",
    "    dary = np.array(data)\n",
    "    dary -= np.average(dary)\n",
    "    step = np.hstack((np.ones(len(dary)), -1*np.ones(len(dary))))\n",
    "    dary_step = np.convolve(dary, step, mode='valid')\n",
    "    # Get the peaks of the convolution\n",
    "    peaks = signal.find_peaks(dary_step, width=10)[0]\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def process_single_audio(file_path, h, completef0 = False):\n",
    "\n",
    "    try:\n",
    "        y, sr = librosa.load(file_path, sr = 300000) # important, garder cette frequence d'echantillognage, sinon faux.\n",
    "\n",
    "        #y = nr.reduce_noise(y1, sr, hop_length = 512, freq_mask_smooth_hz = 1000)\n",
    "        f0,_,_= libf0.salience(y, Fs=sr, N=500, H=h, F_min=40000, F_max=90000, R=10.0, num_harm=10, freq_smooth_len=11, alpha=0.9, gamma=0.0, constraint_region=None, tol=5, score_low=0.01, score_high=1.0)\n",
    "        times = librosa.times_like(f0, sr = sr,  hop_length = h)\n",
    "\n",
    "        #very depend of the F thresholds\n",
    "\n",
    "        # Convolution part\n",
    "        # denoising the extimated f0\n",
    "        x = np.array(f0)\n",
    "        x_std = (x - x.mean()) / x.std()\n",
    "        x_denoiseP = (denoise_tv_chambolle(x_std, weight= 0.5))**2\n",
    "        x_denoiseN = -(denoise_tv_chambolle(x_std, weight=0.5))**2\n",
    "        # find the steps\n",
    "        stepsP = find_steps(x_denoiseP)\n",
    "        stepsN = find_steps(x_denoiseN)\n",
    "\n",
    "        vocf0 = []\n",
    "        voctime = []\n",
    "        vocduration = []\n",
    "        voctotf0 = []\n",
    "        # for each vocalization found in the audio\n",
    "        for i in range(min(len(stepsP), len(stepsN))):\n",
    "            if np.mean(f0[stepsP[i]:stepsN[i]]) < 45000 :\n",
    "                continue\n",
    "            vocf0.append(np.mean(f0[stepsP[i]:stepsN[i]]))\n",
    "            voctotf0.append(f0[stepsP[i]:stepsN[i]])\n",
    "            voctime.append(list(times[stepsP[i]:stepsN[i]]))\n",
    "            vocduration.append(times[stepsN[i]] - times[stepsP[i]])\n",
    "        if not vocf0 :\n",
    "            return None\n",
    "        if completef0 :\n",
    "            return {\n",
    "            'Filename': [file_path.split(\"_\")[-1].split(\".\")[0]]*len(vocf0),\n",
    "            'F0' : voctotf0,\n",
    "            'Duration' : voctime\n",
    "        }\n",
    "        return {\n",
    "            'Filename': [file_path.split(\"_\")[-1].split(\".\")[0]]*len(vocf0),\n",
    "            'F0' : vocf0,\n",
    "            'Duration' : vocduration\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractFeaturesRecordings(file_paths, h):\n",
    "    results = {\n",
    "            'Filename': [],\n",
    "            'Frequency' : [],\n",
    "            'Duration' : [],\n",
    "        }\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        result = process_single_audio(file_path, h)\n",
    "        if result is not None:\n",
    "            results['Filename'].extend(result['Filename'])\n",
    "            results['Frequency'].extend(result['F0'])\n",
    "            results['Duration'].extend(result['Duration'])\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.dropna(axis=0, how='any')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VocAnalysis(playback_time_str, basepath, Feature = \"VocNumber\", thresholds = [0, 100], h=500) :\n",
    "    # TODO : check for method error. (try, except)\n",
    "    listRecordingsPaths = ExtractRecordingsPaths(playback_time_str, basepath)\n",
    "    if len(listRecordingsPaths) == 0 :\n",
    "        return False\n",
    "    FeaturesDF = ExtractFeaturesRecordings(listRecordingsPaths, h)\n",
    "    if Feature == \"VocNumber\" :\n",
    "        if (len(FeaturesDF) >= min(thresholds) and len(FeaturesDF) < max(thresholds)) :\n",
    "            return True\n",
    "    elif Feature == \"Duration\" or Feature == \"Frequency\":\n",
    "        if any(FeaturesDF[Feature] >= min(thresholds)) and any(FeaturesDF[Feature] < max(thresholds)) :\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "playback_time_str = '15-41-48'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\libf0\\salience.py:440: RuntimeWarning: invalid value encountered in cast\n",
      "  bin_index = np.floor((1200 / R) * np.log2(F / F_ref) + 0.5).astype(np.int64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "It took 0.78 second(s) to finish\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "\n",
    "print(VocAnalysis(playback_time_str, basepath, Feature = \"Frequency\", thresholds = [60000, 70000]))\n",
    "\n",
    "finish = time.perf_counter()\n",
    "print(f'It took {finish-start:.2f} second(s) to finish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
